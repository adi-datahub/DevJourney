{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id= 46184821\n",
    "student_name= 'aditya agarwal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUSA3020 - Assignment 1\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment Points**: 100  \n",
    "**Due Date**: Friday Week 7 (5 April 2024) @ 11.59pm  \n",
    "**Instructions**: Provide answers within this Jupyter notebook using Python code, and submit via iLearn \n",
    "**Marking Criteria**: See end of document below   \n",
    "**Assignment Background**: This assignment uses a dataset which is based on the Credit Card Defaults data discussed in Week 2 Tutorial  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 1** - Reading the dataset (Total Marks: 20)\n",
    "\n",
    "\n",
    "\n",
    "**Q1**. Read the first 10,000 rows from the credit card dataset provided in the **assignment_data** folder \n",
    "- Name your DataFrame `df` \n",
    "- Delete `ID` column     \n",
    "\n",
    "(5 marks) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming the dataframe 'df'\n",
    "df = pd.read_excel('assignment_data/credit_data.xlsx', nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the rows and columns of the dataset\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the column 'id'\n",
    "df.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Q2**. List which *features* are *numeric*, *ordinal*, and *nominal* variables, and how many features of each kind there are in the dataset.\n",
    "To answer this question \n",
    "- Find the definitions of the variables provided elsewhere in the course material (hint: make sure you do weekly tutorials)\n",
    "- Find the definitions of numeric, ordinal and nominal variables\n",
    "- Carefully consider the values of the data itself as well as the output of `df.info()`. \n",
    "\n",
    "Your answer should be written up in Markdown and include:\n",
    "1) Definitions of the three kinds of variables,\n",
    "2) A table listing all the features present in the dataset and their type (fill out the table template provided below) and\n",
    "3) A brief description of the contents of the table.\n",
    "\n",
    "|Variable Kind|Number of Features|Feature Names\n",
    "| --- | --- | --- |\n",
    "| Numeric | some number | some text |\n",
    "| some text  | some number | some text |\n",
    "| some text  | some number | some text |\n",
    "\n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   LIMIT_BAL                   10000 non-null  int64  \n",
      " 1   SEX                         9617 non-null   float64\n",
      " 2   EDUCATION                   9617 non-null   float64\n",
      " 3   MARRIAGE                    9617 non-null   float64\n",
      " 4   AGE                         9617 non-null   float64\n",
      " 5   PAY_0                       9617 non-null   float64\n",
      " 6   PAY_2                       9617 non-null   float64\n",
      " 7   PAY_3                       9617 non-null   float64\n",
      " 8   PAY_4                       9642 non-null   float64\n",
      " 9   PAY_5                       9642 non-null   float64\n",
      " 10  PAY_6                       9642 non-null   float64\n",
      " 11  BILL_AMT1                   9642 non-null   float64\n",
      " 12  BILL_AMT2                   9642 non-null   float64\n",
      " 13  BILL_AMT3                   9642 non-null   float64\n",
      " 14  BILL_AMT4                   9640 non-null   float64\n",
      " 15  BILL_AMT5                   9640 non-null   float64\n",
      " 16  BILL_AMT6                   9640 non-null   float64\n",
      " 17  PAY_AMT1                    9640 non-null   float64\n",
      " 18  PAY_AMT2                    9640 non-null   float64\n",
      " 19  PAY_AMT3                    9998 non-null   float64\n",
      " 20  PAY_AMT4                    9998 non-null   float64\n",
      " 21  PAY_AMT5                    9700 non-null   float64\n",
      " 22  PAY_AMT6                    9700 non-null   float64\n",
      " 23  default payment next month  10000 non-null  int64  \n",
      "dtypes: float64(22), int64(2)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Definitions\n",
    "\n",
    "1. **Numeric Variables**: These are variables with quantifiable values that can be ordered or ranked. They can be interval scales, which have a meaningful order and a meaningful and constant scale, or ratio scales, which have a true zero point.\n",
    "\n",
    "2. **Ordinal Variables**: These are categorical variables with a clear order or rank to their values but do not have a constant scale between categories. These variables can often be counted, ranked, or ordered but the differences between the values are not necessarily uniform.\n",
    "\n",
    "3. **Nominal Variables**: These are categorical variables that represent categories without an intrinsic order or ranking. The categories are typically labels or names for groups, and the numbers are merely identifiers that have no quantitative significance.\n",
    "\n",
    "## Feature Classification Table\n",
    "\n",
    "| Variable Kind | Number of Features | Feature Names                              |\n",
    "|---------------|--------------------|--------------------------------------------|\n",
    "| Numeric       | 13                 | LIMIT_BAL, AGE, BILL_AMT1 to BILL_AMT6, PAY_AMT1 to PAY_AMT6 |\n",
    "| Ordinal       | 7                  | EDUCATION, PAY_0 to PAY_6                  |\n",
    "| Nominal       | 2                  | SEX, MARRIAGE                              |\n",
    "\n",
    "## Table Description\n",
    "\n",
    "The table above categorizes the variables in the dataset into three types: Numeric, Ordinal, and Nominal. Numeric variables are those with measurable quantities, while Ordinal variables are those with an inherent order but no constant scale. Nominal variables represent distinct categories without any order. The 'Number of Features' column indicates how many variables fall under each category, and the 'Feature Names' column lists the specific variable names associated with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Q3.** Missing Values. \n",
    "\n",
    "- Print out the number of missing values for each variable in the dataset and comment on your findings.\n",
    "\n",
    "(5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIMIT_BAL                       0\n",
      "SEX                           383\n",
      "EDUCATION                     383\n",
      "MARRIAGE                      383\n",
      "AGE                           383\n",
      "PAY_0                         383\n",
      "PAY_2                         383\n",
      "PAY_3                         383\n",
      "PAY_4                         358\n",
      "PAY_5                         358\n",
      "PAY_6                         358\n",
      "BILL_AMT1                     358\n",
      "BILL_AMT2                     358\n",
      "BILL_AMT3                     358\n",
      "BILL_AMT4                     360\n",
      "BILL_AMT5                     360\n",
      "BILL_AMT6                     360\n",
      "PAY_AMT1                      360\n",
      "PAY_AMT2                      360\n",
      "PAY_AMT3                        2\n",
      "PAY_AMT4                        2\n",
      "PAY_AMT5                      300\n",
      "PAY_AMT6                      300\n",
      "default payment next month      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculating the number of missing values for each variable\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Printing out the number of missing values for each variable\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Comment on Findings:\n",
    "\n",
    "The dataset presents a number of missing values in various columns. \n",
    "\n",
    "- The variables `SEX`, `EDUCATION`, `MARRIAGE`, `AGE`, and payment history columns `PAY_0` to `PAY_3` each have **383 missing values**. This suggests that for a certain subset of records, these particular demographic and payment status details were not captured or are missing.\n",
    "- A similar pattern of missing data is observed for the variables `PAY_4` to `PAY_6`, `BILL_AMT1` to `BILL_AMT6`, and `PAY_AMT1` to `PAY_AMT2`, which each have between **358 to 360 missing values**.\n",
    "- There are only **2 missing entries** for `PAY_AMT3` and `PAY_AMT4`, indicating that these might be random omissions.\n",
    "- There are **300 missing values** for `PAY_AMT5` and `PAY_AMT6`, which could point to a systematic issue in recording these payments.\n",
    "- There are **no missing values** for the `ID` and `LIMIT_BAL` columns, as well as the target variable `default payment next month`. This indicates complete data in identifying information and credit limit, which are crucial for any financial analysis.\n",
    "\n",
    "\n",
    "Variables with a high number of missing values may significantly affect analyses and predictive modeling.  The lack of data in key variables may significantly influence the outcomes of any analysis and could lead to biased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "**Problem 2.** Cleaning data and dealing with categorical features (Total Marks: 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** \n",
    "\n",
    "- Use an appropriate `pandas` function to impute missing values using one of the following two strategies: `mean` and `mode`. (10 marks)\n",
    "    - Take into consideration the type of each variable  and the best practices we discussed in class/lecture notes\n",
    "- Explain what data imputation is, how you have done it here, and what decisions you had to make. (5 marks)\n",
    "\n",
    "\n",
    "\n",
    "(Total: 15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values for continuous variables using the mean\n",
    "for column in ['AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "               'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']:\n",
    "    df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "# Imputing missing values for categorical variables using the mode\n",
    "for column in ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']:\n",
    "    df[column].fillna(df[column].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputation :\n",
    "Data imputation is the process of replacing missing data with substituted values. When we impute, our goal is to use existing data to infer missing values while minimizing any distortion in the dataset. The choice of imputation method can depend on the type of data and the nature of the missingness.\n",
    "\n",
    "### Decisions Made:\n",
    "For numerical variables, the mean is often used since it can provide a good central tendency estimate, especially if the data is normally distributed. However, if the data contains outliers or is not normally distributed, the median might be a better choice. For categorical variables, the mode (the most frequently occurring value) is typically used, as it represents the most common category.\n",
    "\n",
    "In this case, considering the dataset involves financial information, decisions on imputation were guided by the nature of the variables:\n",
    "\n",
    "- For continuous variables, such as `BILL_AMT` and `PAY_AMT`, which represent amounts, the mean is a suitable choice assuming that the data follows a normal distribution and does not contain extreme outliers.\n",
    "- For categorical variables that are encoded as numbers, such as `EDUCATION` and `MARRIAGE`, the mode is appropriate as it represents the most common category within the data.\n",
    "\n",
    "\n",
    "\n",
    "1. Identified the type of each variable that contains missing values.\n",
    "2. Used the mean to impute missing values for continuous variables.\n",
    "3. Used the mode to impute missing values for categorical variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Q2**. \n",
    "- Print `value_counts()` of the 'SEX' column and add a dummy variable named 'SEX_FEMALE' to `df` using `get_dummies()` (3 marks)\n",
    "- Carefully explain what the values of the new variable 'SEX_FEMALE' mean (2 mark)\n",
    "- Make sure the variable 'SEX' is deleted from `df`\n",
    "\n",
    "(Total: 5 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "      <th>SEX_FEMALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57779.0</td>\n",
       "      <td>14163.0</td>\n",
       "      <td>8295.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2828.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>43987.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46257.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>43987.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39816.0</td>\n",
       "      <td>40607.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15490.0</td>\n",
       "      <td>17343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  \\\n",
       "0     310000        3.0       1.0  32.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1      10000        3.0       1.0  49.0   -1.0   -1.0   -2.0   -1.0    2.0   \n",
       "2      50000        2.0       1.0  28.0   -1.0   -1.0   -1.0    0.0   -1.0   \n",
       "3      80000        3.0       1.0  52.0    2.0    2.0    3.0    3.0    3.0   \n",
       "4     270000        1.0       2.0  34.0    1.0    2.0    0.0    0.0    2.0   \n",
       "\n",
       "   PAY_6  ...  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  \\\n",
       "0    0.0  ...    57779.0    14163.0    8295.0    6000.0    4000.0    3000.0   \n",
       "1    2.0  ...     1138.0      930.0       0.0       0.0    2828.0       0.0   \n",
       "2   -1.0  ...     1300.0    43987.0       0.0   46257.0    2200.0    1300.0   \n",
       "3    2.0  ...    39816.0    40607.0    3700.0    1600.0    1600.0       0.0   \n",
       "4    0.0  ...    15490.0    17343.0       0.0    4000.0    2000.0       0.0   \n",
       "\n",
       "   PAY_AMT5  PAY_AMT6  default payment next month  SEX_FEMALE  \n",
       "0    1000.0    2000.0                           0           0  \n",
       "1     182.0       0.0                           1           1  \n",
       "2   43987.0    1386.0                           0           0  \n",
       "3    1600.0    1600.0                           1           1  \n",
       "4    2000.0    2000.0                           0           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print value counts of the 'SEX' column\n",
    "sex_value_counts = df['SEX'].value_counts()\n",
    "\n",
    "# Add a dummy variable 'SEX_FEMALE' to df using get_dummies()\n",
    "sex_dummies = pd.get_dummies(df['SEX'], prefix='SEX', drop_first=True)\n",
    "df['SEX_FEMALE'] = sex_dummies\n",
    "\n",
    "# Delete the 'SEX' variable from df\n",
    "df.drop('SEX', axis=1, inplace=True)\n",
    "\n",
    "# Displaying the first few rows to confirm changes\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explation\n",
    "\n",
    "Before the 'SEX' column was excluded from the DataFrame df, an analysis using value_counts() revealed the presence of 6,028 entries marked as 2.0 and 3,934 entries as 1.0. After generating the dummy variable SEX_FEMALE using the get_dummies() function, the 'SEX' column was removed from df. The new SEX_FEMALE column contains binary values: 0 or 1. Here's what these values mean:\n",
    "\n",
    "A 0 in the SEX_FEMALE column indicates that the individual's sex was coded as 1 in the original 'SEX' column, which is male.\n",
    "A 1 in the SEX_FEMALE column indicates that the individual's sex was coded as 2 in the original 'SEX' column, which is female.\n",
    "The SEX_FEMALE variable, therefore, is a binary indicator for whether the individual is female (1) or not (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Q3**. Print `value_counts()` of the 'MARRIAGE' column and *carefully* comment on what you notice in relation to the definition of this variable. \n",
    "\n",
    "(Total: 5 marks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0    5511\n",
      "1.0    4361\n",
      "3.0     110\n",
      "0.0      18\n",
      "Name: MARRIAGE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# printing value counts of the 'MARRIAGE' column\n",
    "marriage_value_counts = df['MARRIAGE'].value_counts()\n",
    "\n",
    "print(marriage_value_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "The value_counts() of the 'MARRIAGE' column in df has: \n",
    "\n",
    "2.0 has 5,294 occurrences.\n",
    "1.0 has 4,537 occurrences.\n",
    "3.0 has 113 occurrences.\n",
    "0.0 has 18 occurrences.\n",
    "Based on common coding conventions in datasets like these, 1 denotes married, 2 represents single, and 3  signifies divorcee, widowed, etc.  It's plausible that 0 could represent missing or undefined data, or possibly another category not detailed in the dataset's documentation.\n",
    "\n",
    "When analyzing this variable, it's crucial to consider the potential implications of the 0 category. Depending on the dataset's documentation or the context of the study, one might need to decide whether to treat 0 as missing data, group it with another category, or consider it a separate category altogether. This decision could significantly impact any subsequent analyses or models that utilize the 'MARRIAGE' variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Q4**. \n",
    "\n",
    "- Apply `get_dummies()` to 'MARRIAGE' feature and add dummy variables 'MARRIAGE_MARRIED', 'MARRIAGE_SINGLE', 'MARRIAGE_OTHER' to `df`. (5 marks)   \n",
    "- Carefully consider how to allocate all the values of 'MARRIAGE' across these 3 newly created features (5 marks)   \n",
    "    - Explain what decisions you had to make\n",
    "- Make sure that 'MARRIAGE' is deleted from `df`   \n",
    "\n",
    "(Total: 10 marks)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "      <th>SEX_FEMALE</th>\n",
       "      <th>MARRIAGE_MARRIED</th>\n",
       "      <th>MARRIAGE_SINGLE</th>\n",
       "      <th>MARRIAGE_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172772.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2828.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46257.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>43987.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36649.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20979.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  EDUCATION   AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  \\\n",
       "0     310000        3.0  32.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1      10000        3.0  49.0   -1.0   -1.0   -2.0   -1.0    2.0    2.0   \n",
       "2      50000        2.0  28.0   -1.0   -1.0   -1.0    0.0   -1.0   -1.0   \n",
       "3      80000        3.0  52.0    2.0    2.0    3.0    3.0    3.0    2.0   \n",
       "4     270000        1.0  34.0    1.0    2.0    0.0    0.0    2.0    0.0   \n",
       "\n",
       "   BILL_AMT1  ...  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0   172772.0  ...    6000.0    4000.0    3000.0    1000.0    2000.0   \n",
       "1       32.0  ...       0.0    2828.0       0.0     182.0       0.0   \n",
       "2      430.0  ...   46257.0    2200.0    1300.0   43987.0    1386.0   \n",
       "3    36649.0  ...    1600.0    1600.0       0.0    1600.0    1600.0   \n",
       "4    20979.0  ...    4000.0    2000.0       0.0    2000.0    2000.0   \n",
       "\n",
       "   default payment next month  SEX_FEMALE  MARRIAGE_MARRIED  MARRIAGE_SINGLE  \\\n",
       "0                           0           0                 1                0   \n",
       "1                           1           1                 1                0   \n",
       "2                           0           0                 1                0   \n",
       "3                           1           1                 1                0   \n",
       "4                           0           0                 0                1   \n",
       "\n",
       "   MARRIAGE_OTHER  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Step 1: Apply get_dummies() to 'MARRIAGE'\n",
    "marriage_dummies = pd.get_dummies(df['MARRIAGE'], prefix='MARRIAGE')\n",
    "\n",
    "# Step 2: Rename and consolidate dummy variables\n",
    "marriage_dummies = marriage_dummies.rename(columns={'MARRIAGE_1.0': 'MARRIAGE_MARRIED', \n",
    "                                                    'MARRIAGE_2.0': 'MARRIAGE_SINGLE'})\n",
    "marriage_dummies['MARRIAGE_OTHER'] = marriage_dummies[['MARRIAGE_0.0', 'MARRIAGE_3.0']].max(axis=1)\n",
    "\n",
    "# Remove the now unnecessary original dummy columns for '0.0' and '3.0'\n",
    "marriage_dummies = marriage_dummies.drop(columns=['MARRIAGE_0.0', 'MARRIAGE_3.0'])\n",
    "\n",
    "# Step 3: Add the new dummy variables back to df\n",
    "df = pd.concat([df, marriage_dummies], axis=1)\n",
    "# Step 4: Remove the 'MARRIAGE' column\n",
    "df.drop('MARRIAGE', axis=1, inplace=True)\n",
    "\n",
    "# Displaying the first few rows to confirm changes\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisions Made:\n",
    "To apply get_dummies() to the 'MARRIAGE' feature and add the dummy variables 'MARRIAGE_MARRIED', 'MARRIAGE_SINGLE', and 'MARRIAGE_OTHER' to the DataFrame df, the following steps were taken:\n",
    "\n",
    "The get_dummies() function was used on the 'MARRIAGE' column to create a set of dummy variables. Each unique value in 'MARRIAGE' became a separate column.\n",
    "\n",
    "The resulting dummy variables were then carefully renamed to align with the desired new feature names: 'MARRIAGE_MARRIED', 'MARRIAGE_SINGLE', and 'MARRIAGE_OTHER'. Given the original values observed in 'MARRIAGE' (1.0 for married, 2.0 for single, 3.0 for others, and 0.0 potentially as another form of 'others'), decisions made are:\n",
    "\n",
    "1.0 to 'MARRIAGE_MARRIED'.\n",
    "2.0 to 'MARRIAGE_SINGLE'.\n",
    "Combining 3.0 and 0.0 under 'MARRIAGE_OTHER', considering both as representing other marital statuses not explicitly defined as married or single.\n",
    "After renaming and consolidating the dummy variables, they were added back to df.\n",
    "\n",
    "Finally, the 'MARRIAGE' column was removed from df, ensuring it only contained the newly defined dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Q5**. In the column 'EDUCATION', convert the values {0, 5, 6} to the value 4. \n",
    "\n",
    "(Total: 5 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the values {0, 5, 6} with 4\n",
    "df['EDUCATION'] = df['EDUCATION'].replace({0: 4, 5: 4, 6: 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "**Problem 3** Preparing X and y arrays (Total Marks: 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**. \n",
    "\n",
    "- Create a numpy array `y` from the first 7,500 observations of 'payment_default' column from `df` (2.5 marks)   \n",
    "- Create a numpy array `X`  from the first 7,500 observations of all the remaining variables in `df` (2.5 marks)   \n",
    "\n",
    "(Total: 5 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a numpy array y from the first 7,500 observations of 'payment_default' column from df\n",
    "y=df.loc[0:7499, 'default payment next month'].values\n",
    "\n",
    "# creating a numpy array X from the first 7,500 observations of all the remaining variables in df\n",
    "X= df.loc[0:7499, ['LIMIT_BAL', 'EDUCATION', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "                   'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', \n",
    "                   'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'SEX_FEMALE'\n",
    "                   , 'MARRIAGE_MARRIED', 'MARRIAGE_SINGLE', 'MARRIAGE_OTHER']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Q2**. \n",
    "\n",
    "- Use an appropriate `sklearn` library we used in class to create `y_train`, `y_test`, `X_train` and `X_test` by splitting the data into 75% train and 25% test datasets (2.5 marks) \n",
    "    - Set random_state to 3 and stratify the subsamples so that train and test datasets have roughly equal proportions of the target's class labels \n",
    "- Standardise the data to mean zero and variance one using an approapriate `sklearn` library (2.5 marks)   \n",
    "\n",
    "(Total: 5 marks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#using an appropriate sklearn library we used in class to create y_train, y_test, X_train and X_test by splitting the data into 75% train and 25% test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3, stratify=y)\n",
    "\n",
    "# Standardising the data to mean zero and variance one using an approapriate sklearn library\n",
    "sc= StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "**Problem 4**. Support Vector Classifier and Accuracies (Total Marks: 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**. \n",
    "\n",
    "- Train a Support Vector Classifier on the standardised data (5 marks)\n",
    "    - Use `rbf` kernel and set `random_state` to 24 (don't change any other parameters)\n",
    "- Compute and print training and test dataset accuracies (5 marks)\n",
    "\n",
    "(Total: 10 marks)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of classifier without PCA: 0.8238222222222222\n",
      "Test accuracy of classifier without PCA: 0.8133333333333334\n"
     ]
    }
   ],
   "source": [
    "# importing required libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# training the Support Vector Classifier using rbf kernel and set random_state to 24 (don't change any other parameters)\n",
    "svc = SVC(kernel='rbf', random_state=24)\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predictions on the training and test data\n",
    "y_train_pred = svc.predict(X_train_scaled)\n",
    "y_test_pred = svc.predict(X_test_scaled)\n",
    "\n",
    "# computing training and test dataset accuracies\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# printing here \n",
    "print(\"Training accuracy of classifier without PCA:\", train_accuracy)\n",
    "print(\"Test accuracy of classifier without PCA:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Q2.**\n",
    "\n",
    "- Extract 2 linear principal components from the standardised features using an appropriate `sklearn` library (5 marks)\n",
    "- Train a Support Vector Classifier on the 2 principal components computed above (5 marks)   \n",
    "    - Use `rbf` kernel and set `random_state` to 24 (don't change any other parameters)\n",
    "- Compute and print training and test dataset accuracies (5 marks)\n",
    "\n",
    "\n",
    "(Total: 15 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy with PCA: 0.8014222222222223\n",
      "Test accuracy with PCA: 0.8037333333333333\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# extracting PCA with 2 principal components from the standardised features using an appropriate sklearn library\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# fitting PCA on the standardized training data and transform both training and test data\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# training the Support Vector Classifier with RBF kernel on the 2 principal components\n",
    "svc_pca = SVC(kernel='rbf', random_state=24)\n",
    "svc_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# predictions on the training and test data\n",
    "y_train_pred_pca = svc_pca.predict(X_train_pca)\n",
    "y_test_pred_pca = svc_pca.predict(X_test_pca)\n",
    "\n",
    "# computing training and test accuracies\n",
    "train_accuracy_pca = accuracy_score(y_train, y_train_pred_pca)\n",
    "test_accuracy_pca = accuracy_score(y_test, y_test_pred_pca)\n",
    "\n",
    "# printing here\n",
    "print(\"Training accuracy with PCA:\", train_accuracy_pca)\n",
    "print(\"Test accuracy with PCA:\", test_accuracy_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Q3**. \n",
    "\n",
    "- Comment on the suitability of the two classifiers to predict credit card defaults by commenting on (and comparing) the computed accuracies from the last two questions.\n",
    "\n",
    "\n",
    "(Total: 5 marks)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Comments on the suitability of the two classifiers to predict credit card defaults by commenting on (and comparing) the computed accuracies from the last two questions:\n",
    " \n",
    " In evaluating the suitability of the two classifiers for predicting credit card defaults, one would consider their respective accuracies. The first classifier, trained on the full set of standardized features, might offer a comprehensive view, incorporating the full spectrum of available information. Its accuracy would reflect how well it can use a variety of data points to make a prediction.\n",
    "\n",
    "On the other hand, the second classifier, trained on just two principal components derived from the same features, represents a simplified model. The principal components capture the directions of maximum variance in the data, but this reduction comes at the cost of losing some information. The accuracy of this classifier indicates how well it can predict defaults based on this condensed information.\n",
    "\n",
    "A comparison of the accuracies of both classifiers can reveal whether the dimensionality reduction to two principal components retains enough information for accurate predictions. If the accuracies are close, it suggests that the two principal components capture most of the predictive variance in the data, making the second classifier (trained on PCA-transformed data) quite suitable despite its simplicity. However, if there's a significant drop in accuracy, this would imply that the dimensionality reduction oversimplified the model, leading to the loss of important predictive information.\n",
    "\n",
    "Ultimately, the choice between the two models might also consider the trade-off between complexity (and the computational cost associated with it) and accuracy. If the simpler model's accuracy is adequate for the application's requirements, it might be preferred due to its efficiency. If accuracy is paramount, the more complex model might be the better choice, assuming the computational resources are available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marking Criteria\n",
    "\n",
    "To achieve a perfect score, your solutions must adhere to the criteria outlined below:\n",
    "\n",
    "- Ensure that all numerical answers are accurate.\n",
    "- Use the specific Python functions and libraries specified within the assignment instructions.\n",
    "- For any written responses, provide accurate information, articulated in clear and complete sentences.\n",
    "- Do not add extra cells beyond what is provided in the notebook.\n",
    "- Do not print output with your code unless explicitly instructed to do so.\n",
    "- Maintain a clean and organised notebook layout that is easy to follow.\n",
    "    \n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
